SVM with RBF Kernel - Dual Optimization 🧿
<br>
<br>
😖 Boring Part (Implementation 🥱):
<br>
This project implements a Support Vector Machine (SVM) using the Radial Basis Function (RBF) kernel to classify digits (0 and 1) from the MNIST dataset. The classifier is optimized by solving the dual problem using quadratic programming with cvxopt. Oh, you don’t know what the dual optimization problem is? You scikit-sh*t 🤡🤡.
<br>
<br>
🚀 Features
Dual Optimization: Solves the SVM dual problem via quadratic programming for exact margin maximization. Why are you still reading? Just go and use scikit-learn, you sl*t 🤖.
<br>
<br>
⌨️Efficient Training: Optimized to run on a balanced subset of the MNIST dataset (1000 examples). Hey, it's okay, bro—I don’t use vectorization that much, so it’s hard to iterate over a large dataset. Now, you’ll ask, "Hey, why don’t you use vectorization?" Good question. Take that question, roll it up, and shove it where the sun doesn't shine. Thank you 👍.

👋Bias Calculation: Includes bias averaging over support vectors.

📁 Dataset
The project uses the MNIST dataset for classifying digits 0 and 1. The dataset is already pre-processed and scaled for SVM training.

Training Set: 500 examples of digit 0 and 500 examples of digit 1.

Test Set: Provided separately for evaluating the model.


🔌Dataset Instructions:
If you're cloning this repository, download the dataset from the MNIST Official Website or from this repository. Place the dataset in the same directory as the code for easy access. 

🫶 License:
Do whatever you want with this sh*t—just don’t blame me if it blows up your laptop 💻 or PC. And one last thing: if you hate your house, you can just iterate over all examples of the dataset, and your house will burn in flames. So that’s it, bye. Remember, we have only one goal: a hole 🫵🫵. 
