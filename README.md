SVM with RBF Kernel - Dual Optimization ğŸ§¿
<br>
<br>
ğŸ˜– Boring Part (Implementation ğŸ¥±):
<br>
This project implements a Support Vector Machine (SVM) using the Radial Basis Function (RBF) kernel to classify digits (0 and 1) from the MNIST dataset. The classifier is optimized by solving the dual problem using quadratic programming with cvxopt. Oh, you donâ€™t know what the dual optimization problem is? You scikit-sh*t ğŸ¤¡ğŸ¤¡.
<br>
<br>
ğŸš€ Features
Dual Optimization: Solves the SVM dual problem via quadratic programming for exact margin maximization. Why are you still reading? Just go and use scikit-learn, you sl*t ğŸ¤–.
<br>
<br>
âŒ¨ï¸Efficient Training: Optimized to run on a balanced subset of the MNIST dataset (1000 examples). Hey, it's okay, broâ€”I donâ€™t use vectorization that much, so itâ€™s hard to iterate over a large dataset. Now, youâ€™ll ask, "Hey, why donâ€™t you use vectorization?" Good question. Take that question, roll it up, and shove it where the sun doesn't shine. Thank you ğŸ‘.

ğŸ‘‹Bias Calculation: Includes bias averaging over support vectors.

ğŸ“ Dataset
The project uses the MNIST dataset for classifying digits 0 and 1. The dataset is already pre-processed and scaled for SVM training.

Training Set: 500 examples of digit 0 and 500 examples of digit 1.

Test Set: Provided separately for evaluating the model.


ğŸ”ŒDataset Instructions:
If you're cloning this repository, download the dataset from the MNIST Official Website or from this repository. Place the dataset in the same directory as the code for easy access. 

ğŸ«¶ License:
Do whatever you want with this sh*tâ€”just donâ€™t blame me if it blows up your laptop ğŸ’» or PC. And one last thing: if you hate your house, you can just iterate over all examples of the dataset, and your house will burn in flames. So thatâ€™s it, bye. Remember, we have only one goal: a hole ğŸ«µğŸ«µ. 
